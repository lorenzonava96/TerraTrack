{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lorenzonava96/TerraTrack.git\n",
        "!pip uninstall earthengine-api -y\n",
        "!pip uninstall geemap -y\n",
        "!pip install -r TerraTrack/requirements.txt\n",
        "# !pip install --upgrade earthengine-api geemap"
      ],
      "metadata": {
        "id": "ANCSWCqTbRPU"
      },
      "id": "ANCSWCqTbRPU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LvPB1GpDrlGg",
      "metadata": {
        "id": "LvPB1GpDrlGg"
      },
      "outputs": [],
      "source": [
        "import rasterio\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage import exposure\n",
        "from datetime import datetime\n",
        "from scipy.ndimage import convolve\n",
        "from scipy.signal import medfilt\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import ee\n",
        "import geemap\n",
        "from TerraTrack.src import *\n",
        "\n",
        "output_dir = 'outputs'\n",
        "\n",
        "ee.Authenticate(auth_mode='notebook')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efdef515",
      "metadata": {
        "id": "efdef515"
      },
      "source": [
        "### **Define Area of Interest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "woZrRkTdL235",
      "metadata": {
        "id": "woZrRkTdL235"
      },
      "outputs": [],
      "source": [
        "# Create a Map instance\n",
        "Map = geemap.Map()\n",
        "\n",
        "# Add a satellite basemap for visualization (similar to Google Earth)\n",
        "Map.add_basemap('HYBRID')\n",
        "\n",
        "# Center the map globally\n",
        "Map.setCenter(0, 0, 2)  # Center on the world with zoom level 2\n",
        "\n",
        "# Display the map for user interaction\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4801b4a",
      "metadata": {
        "id": "c4801b4a"
      },
      "source": [
        "### **Filter S2 Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oMW3qkYorlX3",
      "metadata": {
        "id": "oMW3qkYorlX3"
      },
      "outputs": [],
      "source": [
        "# Define filtering parameters\n",
        "SUMMER_START = '-01-01'       # Start of seasonal filter (MM-DD)\n",
        "SUMMER_END = '-12-30'         # End of seasonal filter (MM-DD)\n",
        "START_YEAR = 2015             # First year to include\n",
        "END_YEAR = 2025               # Last year to include\n",
        "start_date = None     # Optional: remove images before this date ('YYYY-MM-DD')\n",
        "final_date = None     # Optional: limit images up to this date ('YYYY-MM-DD')\n",
        "\n",
        "# Image and mask filtering\n",
        "CLOUD_COVER_MAX = 50          # Max allowable cloud cover per tile (%)\n",
        "N_PER_YEAR = 5               # Max number of images sampled per year\n",
        "mask_water = False            # Enable NDWI-based water masking\n",
        "check_clouds = True           # Remove images with too much cloud in the ROI\n",
        "cloud_threshold = 5           # Max allowable cloud cover in ROI (%)\n",
        "check_snow = True            # Remove images with excessive snow in ROI\n",
        "snow_threshold = 5            # Max allowable snow cover in ROI (%)\n",
        "\n",
        "# Define region of interest from drawn features\n",
        "roi = ee.FeatureCollection(Map.draw_features).geometry()\n",
        "\n",
        "# Process Sentinel-2 imagery and extract terrain data\n",
        "final_collection, morpho = process_sentinel2_data(\n",
        "    roi, START_YEAR, END_YEAR, SUMMER_START, SUMMER_END,\n",
        "    cloud_cover_max=CLOUD_COVER_MAX,\n",
        "    n_per_year=N_PER_YEAR,\n",
        "    mask_water=mask_water,\n",
        "    check_clouds=check_clouds,\n",
        "    cloud_threshold=cloud_threshold,\n",
        "    check_snow=check_snow,\n",
        "    snow_threshold=snow_threshold,\n",
        "    start_date=start_date,\n",
        "    final_date=final_date\n",
        ")\n",
        "\n",
        "# Print the size of the filtered image collection\n",
        "print(\"Final collection size:\", final_collection.size().getInfo())\n",
        "\n",
        "# Print acquisition dates of selected images\n",
        "dates = final_collection.aggregate_array('system:time_start') \\\n",
        "    .map(lambda d: ee.Date(d).format('YYYY-MM-dd')).getInfo()\n",
        "\n",
        "print(\"Acquisition dates in final_collection:\")\n",
        "for d in dates:\n",
        "    print(d)\n",
        "\n",
        "print(\"Processing completed. Final collection and morpho are ready to be downloaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ORwa66YM-HMA",
      "metadata": {
        "id": "ORwa66YM-HMA"
      },
      "source": [
        "### **Downloading Processed Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B63tSIo3rlar",
      "metadata": {
        "id": "B63tSIo3rlar"
      },
      "outputs": [],
      "source": [
        "results = export_s2_composite_morpho_and_metadata(\n",
        "    final_collection=final_collection,\n",
        "    morpho=morpho,\n",
        "    roi=roi,\n",
        "    output_dir=output_dir\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zUcIuMVfOmbR",
      "metadata": {
        "id": "zUcIuMVfOmbR"
      },
      "source": [
        "### **Processing Sentinel-2 Composite**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1xeuoEG2loba",
      "metadata": {
        "id": "1xeuoEG2loba"
      },
      "outputs": [],
      "source": [
        "process_composite_image(output_dir=output_dir, selection_method=\"auto\")  #auto, manual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MPi2Uca9vn9K",
      "metadata": {
        "id": "MPi2Uca9vn9K"
      },
      "outputs": [],
      "source": [
        "composite_path = f\"{output_dir}/S2_Composite_Filtered_8bit.tif\"\n",
        "\n",
        "orig, preprocessed_stack, zero_mask, orig_masked = load_and_preprocess_stack(\n",
        "    composite_path=composite_path,\n",
        "    preprocess_image_stack=preprocess_image_stack,\n",
        "    method=\"cross_corr\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11VevUya_uAG",
      "metadata": {
        "id": "11VevUya_uAG"
      },
      "source": [
        "### **Defining Date Pairs for Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f54bc7c7",
      "metadata": {
        "id": "f54bc7c7"
      },
      "outputs": [],
      "source": [
        "min_separation = 1 # in years\n",
        "max_separation = 5 # in years\n",
        "reference_date = None # YYYY-MM-DD in case of a known constraint motion at a given time (e.g. earthquake)\n",
        "\n",
        "dat1, dat2, separation, datax = define_date_pairs(f\"{output_dir}/Updated_Metadata.csv\",\n",
        "                                                  min_separation=min_separation,\n",
        "                                                  max_separation=max_separation,\n",
        "                                                  reference_date=reference_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bd7f772",
      "metadata": {
        "id": "8bd7f772"
      },
      "source": [
        "# **Feature Tracking Core**\n",
        "\n",
        "### **Test on a Single Image Pair**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f92475de",
      "metadata": {
        "id": "f92475de"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# --- Select Image Pair from Stack ---\n",
        "# (Band indices: 0-based)\n",
        "img1 = preprocessed_stack[:, :, 1]\n",
        "img2 = preprocessed_stack[:, :, 20]\n",
        "\n",
        "# --- Feature Tracking Parameters ---\n",
        "method = 'block_matching'            # 'block_matching' or 'optical_flow'\n",
        "match_func = 'fft_pcc'               # 'fft_ncc', 'fft_pcc', 'phase_cross_corr', or 'mean_optical_flow'\n",
        "subpixel_method = 'parabolic'        # center_of_mass, parabolic, centroid, gaussian, os3, os5, os7, ipg, ensemble\n",
        "\n",
        "block_size = 16\n",
        "overlap = 0.8\n",
        "\n",
        "# --- Displacement Limits ---\n",
        "min_displacement = 0.1\n",
        "max_displacement = 5\n",
        "\n",
        "# --- Filtering Options ---\n",
        "filter_params = {\n",
        "    \"apply_magnitude_filter\": True,          # Remove displacements below/above thresholds\n",
        "    \"min_magnitude\": min_displacement,                      # Minimum accepted motion\n",
        "    \"max_magnitude\": max_displacement,       # Maximum accepted motion (usually block_size - 1)\n",
        "    \"apply_zero_mask_filter\": False,         # Exclude pixels masked in any image (e.g., water/clouds)\n",
        "    \"apply_deviation_filter\": False,         # Remove vectors far from statistical mean\n",
        "    \"std_factor\": 2.5,                       # Standard deviation threshold for deviation filter\n",
        "    \"apply_remove_median_displacement\": True,  # Subtract overall median motion (e.g., camera jitter)\n",
        "    \"apply_median_filter_step\": False,       # Smooth vectors using a median filter\n",
        "    \"filter_size\": 5,                        # Size of median filter kernel (if used)\n",
        "    \"apply_angular_coherence_filter\": False, # Remove vectors that don‚Äôt align with dominant motion\n",
        "    \"angular_threshold\": 50,                 # Max angular deviation (degrees)\n",
        "    \"smoothing_sigma\": 1,                    # Angular coherence smoothing parameter\n",
        "    \"apply_erratic_displacement_filter\": False,  # Remove isolated, noisy vectors\n",
        "    \"neighborhood_size\": 20,                 # Radius for local filtering\n",
        "    \"deviation_threshold\": 2.0,              # Threshold for local deviation\n",
        "    \"apply_pkr_filter\": True,                # Remove low-quality matches using PKR\n",
        "    \"pkr_threshold\": 1.3,                    # Minimum accepted peak-to-residual ratio\n",
        "    \"apply_snr_filter\": True,                # Remove low-confidence vectors based on SNR\n",
        "    \"snr_threshold\": 3,                      # Minimum signal-to-noise ratio\n",
        "}\n",
        "\n",
        "# --- Run Displacement Analysis ---\n",
        "start_time = time.time()\n",
        "\n",
        "u, v, feature_points, pkr, snr = displacement_analysis(\n",
        "    img1=img1,\n",
        "    img2=img2,\n",
        "    method=method,\n",
        "    block_size=block_size,\n",
        "    overlap=overlap,\n",
        "    match_func=match_func,\n",
        "    subpixel_method=subpixel_method,\n",
        "    zero_mask=zero_mask,\n",
        "    filter_params=filter_params,\n",
        "    plot=True,\n",
        "    arrow_scale=0.1\n",
        ")\n",
        "\n",
        "full_feature_points = feature_points  # Store full-resolution grid\n",
        "\n",
        "# --- Timing ---\n",
        "elapsed_time = time.time() - start_time\n",
        "print(f\"BLOCK MATCHING ‚Äî Process completed in {elapsed_time:.2f} seconds (1 pair).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BvmuPi1O1qiJ",
      "metadata": {
        "id": "BvmuPi1O1qiJ"
      },
      "outputs": [],
      "source": [
        "# Estimate total processing time for all image pairs\n",
        "num_pairs = len(separation)  # List of valid date pairs (from earlier step)\n",
        "estimated_total_time = elapsed_time * num_pairs / 60  # in minutes\n",
        "\n",
        "print(f\"‚è±Ô∏è Estimated total processing time for {num_pairs} pairs: {estimated_total_time:.1f} minutes (with parallel computing it'll be faster)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4JO8n1i36sBu",
      "metadata": {
        "id": "4JO8n1i36sBu"
      },
      "source": [
        "### **Processing Image Pairs for Displacement Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c689b76",
      "metadata": {
        "id": "9c689b76",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# FT parameters\n",
        "method = 'block_matching' # block_matching, optical_flow\n",
        "match_func = 'fft_pcc'      # 'fft_ncc', 'fft_pcc', 'phase_cross_corr', or 'mean_optical_flow'\n",
        "subpixel_method='parabolic' # center_of_mass, parabolic, gaussian, os3, os5, os7, ipg, ensemble\n",
        "block_size = 16\n",
        "overlap = 0.8\n",
        "\n",
        "# Filter parameters must be all off here\n",
        "filter_params = {\n",
        "    \"apply_magnitude_filter\": False,\n",
        "    \"min_magnitude\": 0,\n",
        "    \"max_magnitude\": max_displacement,\n",
        "    \"apply_zero_mask_filter\": False,\n",
        "    \"apply_deviation_filter\": False,\n",
        "    \"std_factor\": 2.5,\n",
        "    \"apply_remove_median_displacement\": False,\n",
        "    \"apply_median_filter_step\": False,\n",
        "    \"filter_size\": 5,\n",
        "    \"apply_angular_coherence_filter\": False,\n",
        "    \"angular_threshold\": 50,\n",
        "    \"smoothing_sigma\": 1,\n",
        "    \"apply_erratic_displacement_filter\": False,\n",
        "    \"neighborhood_size\": 20,\n",
        "    \"deviation_threshold\": 2.0,\n",
        "    'apply_pkr_filter': False,\n",
        "    'pkr_threshold': 1.3,\n",
        "    'apply_snr_filter': False,\n",
        "    'snr_threshold': 3,\n",
        "}\n",
        "\n",
        "# Run the processing function\n",
        "results = process_image_pairs(\n",
        "    dat1=dat1,\n",
        "    dat2=dat2,\n",
        "    datax=datax,\n",
        "    preprocessed_stack=preprocessed_stack,\n",
        "    zero_mask=zero_mask,\n",
        "    filter_params=filter_params,\n",
        "    method=method,\n",
        "    block_size=block_size,\n",
        "    overlap=overlap,\n",
        "    match_func=match_func,\n",
        "    subpixel_method=subpixel_method,\n",
        "    max_workers=12,\n",
        "    parallel=True)\n",
        "\n",
        "print('FINALLY DONE !')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "x7XTDQrl7a9n",
      "metadata": {
        "id": "x7XTDQrl7a9n"
      },
      "source": [
        "### **Saving Raw Feature Tracking (FT) Output**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4VQCqdpi2ua0",
      "metadata": {
        "id": "4VQCqdpi2ua0"
      },
      "outputs": [],
      "source": [
        "data = handle_predictions(\n",
        "    output_dir=output_dir,\n",
        "    method=method,\n",
        "    match_func=match_func,\n",
        "    results=results,\n",
        "    separation=separation,\n",
        "    orig=orig,\n",
        "    dat1=dat1,\n",
        "    dat2=dat2,\n",
        "    save=True,\n",
        "    load=True\n",
        ")\n",
        "\n",
        "# Access variables\n",
        "all_u = data['all_u']\n",
        "all_v = data['all_v']\n",
        "all_feature_points = data['all_feature_points']\n",
        "all_pkrs = data['all_pkrs']\n",
        "all_snrs = data['all_snrs']\n",
        "separation = data['separation']\n",
        "study_area_image = data['study_area_image']\n",
        "dat1 = data['dat1']\n",
        "dat2 = data['dat2']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "betNjykSnE3J",
      "metadata": {
        "id": "betNjykSnE3J"
      },
      "source": [
        "### **Pairwise Filtering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f7907ad",
      "metadata": {
        "id": "7f7907ad"
      },
      "outputs": [],
      "source": [
        "custom = {\n",
        "        \"apply_magnitude_filter\": True,\n",
        "        \"min_magnitude\": 0,\n",
        "        \"max_magnitude\": block_size - 1,\n",
        "        \"apply_zero_mask_filter\": False,\n",
        "        \"apply_deviation_filter\": False,\n",
        "        \"std_factor\": 2.5,\n",
        "        \"apply_remove_median_displacement\": True,\n",
        "        \"apply_median_filter_step\": False,\n",
        "        \"filter_size\": 5,\n",
        "        \"apply_angular_coherence_filter\": False,\n",
        "        \"angular_threshold\": 50,\n",
        "        \"smoothing_sigma\": 1,\n",
        "        \"apply_erratic_displacement_filter\": False,\n",
        "        \"neighborhood_size\": 20,\n",
        "        \"deviation_threshold\": 2.0,\n",
        "        \"apply_pkr_filter\": True,\n",
        "        \"pkr_threshold\": 1.3,\n",
        "        \"apply_snr_filter\": True,\n",
        "        \"snr_threshold\": 3,\n",
        "}\n",
        "\n",
        "filtered_all_u, filtered_all_v, filtered_all_feature_points, used_params = filter_all_pairs(\n",
        "    all_u, all_v, all_feature_points, all_pkrs, all_snrs,\n",
        "    filter_displacements=filter_displacements,\n",
        "    block_size=block_size,\n",
        "    zero_mask=zero_mask,\n",
        "    filter_params=custom,\n",
        "    strict_quality_alignment=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "shZ_j7tbtYrN",
      "metadata": {
        "id": "shZ_j7tbtYrN"
      },
      "source": [
        "### **Median Displacement Computation**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OVf9mrzym-7_",
      "metadata": {
        "id": "OVf9mrzym-7_"
      },
      "outputs": [],
      "source": [
        "pixel_size = 10   # Pixel resolution in meters\n",
        "apply_slope_correction=False # Correct estimates according to slope angle\n",
        "\n",
        "# Resample morpho image to match `study_area_image` shape\n",
        "morpho_path = f\"{output_dir}/morpho.tif\"\n",
        "output_path = f\"{output_dir}/resampled_morpho.tif\"\n",
        "resampled_morpho_path, resampled_transform = resample_morpho_to_match(study_area_image.shape, morpho_path, output_path)\n",
        "\n",
        "# Open and plot the resampled DEM, slope, and aspect\n",
        "with rasterio.open(resampled_morpho_path) as src:\n",
        "    resampled_dem = src.read(1)  # Band 1: Resampled DEM\n",
        "    resampled_slope = src.read(2)  # Band 2: Resampled slope\n",
        "    resampled_aspect = src.read(3)  # Band 3: Resampled aspect\n",
        "\n",
        "# Step 1: Accumulate Displacements\n",
        "displacement_data = accumulate_displacement(filtered_all_u, filtered_all_v, filtered_all_feature_points, separation)\n",
        "\n",
        "# Step 2: Calculate Median Displacement\n",
        "median_feature_points, median_u, median_v, median_magnitude, median_angles = calculate_median_displacement(displacement_data, pixel_size, slope_map=resampled_slope, apply_slope_correction=apply_slope_correction)\n",
        "\n",
        "plot_displacement_field(median_feature_points, median_u, median_v, median_magnitude, study_area_image, arrow_scale=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AT4g2-3Lt6Y8",
      "metadata": {
        "id": "AT4g2-3Lt6Y8"
      },
      "source": [
        "### **Final Displacement Filtering & Visualization**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3rgYSxGcm-2P",
      "metadata": {
        "id": "3rgYSxGcm-2P"
      },
      "outputs": [],
      "source": [
        "# Specify which filters to use & define parameters\n",
        "manual_threshold=0.2                   # If None, 95th percentile is used\n",
        "\n",
        "use_angular_coherence = True            # Use angular coherence filter\n",
        "angular_threshold_degrees = 30          # Angular threshold in degrees\n",
        "use_slope_filter = True                 # Skip slope filter\n",
        "min_slope_threshold = 5                 # Minimum slope in degrees\n",
        "use_aspect_filter = True                # Use aspect filter\n",
        "aspect_tolerance = 90                   # Allowable deviation from downslope direction in degrees\n",
        "use_clustering = True                   # Skip clustering filter\n",
        "clustering_params = (20, 9)             # Clustering parameters: (eps, min_samples)\n",
        "\n",
        "arrow_scale = 0.3                       # Scale of the vector arrow\n",
        "\n",
        "fil_median_feature_points, fil_median_u, fil_median_v, fil_median_magnitude = filter_final_map(\n",
        "    median_feature_points, median_u, median_v, median_magnitude, median_angles,\n",
        "    resampled_slope, resampled_aspect, study_area_image,\n",
        "    angular_threshold_degrees=angular_threshold_degrees, min_slope_threshold=min_slope_threshold,\n",
        "    aspect_tolerance=aspect_tolerance, smoothing_sigma=1, clustering_params=clustering_params,\n",
        "    use_angular_coherence=use_angular_coherence, use_slope_filter=use_slope_filter,\n",
        "    use_aspect_filter=use_aspect_filter, use_clustering=use_clustering, arrow_scale=arrow_scale,\n",
        "    manual_threshold=manual_threshold\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mqgYU9k1yYbv",
      "metadata": {
        "id": "mqgYU9k1yYbv"
      },
      "source": [
        "### **Generating & Saving Motion Colormap**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XBDIiRBgq5Ai",
      "metadata": {
        "id": "XBDIiRBgq5Ai"
      },
      "outputs": [],
      "source": [
        "# From cartesian to raster\n",
        "\n",
        "# filtered map\n",
        "fil_u_map, fil_v_map, fil_magnitude_map, fil_angle_map = create_raster_maps(\n",
        "    fil_median_feature_points, fil_median_u, fil_median_v, study_area_image, block_size, overlap\n",
        ")\n",
        "\n",
        "# full map\n",
        "u_map, v_map, magnitude_map, angle_map = create_raster_maps(\n",
        "    median_feature_points, median_u, median_v, study_area_image, block_size, overlap\n",
        ")\n",
        "\n",
        "processed_mask = process_mask(fil_magnitude_map)\n",
        "\n",
        "masked_magnitude = np.where(processed_mask, magnitude_map, np.nan)\n",
        "\n",
        "orig_path = f'{output_dir}/S2_Composite_Filtered_8bit.tif'\n",
        "output_path = f\"{output_dir}/output_motion_colormap.tif\"\n",
        "\n",
        "# Generate the magnitude map\n",
        "overlay_magnitude_map(orig[..., 0], masked_magnitude, block_size=block_size, overlap=overlap)\n",
        "\n",
        "save_as_geotiff(orig_path, output_path, masked_magnitude, block_size, overlap)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-mOJk3L7ycDA",
      "metadata": {
        "id": "-mOJk3L7ycDA"
      },
      "source": [
        "### **Time Series Reconstruction & Velocity Estimation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C4C3c4D3q-pG",
      "metadata": {
        "id": "C4C3c4D3q-pG"
      },
      "outputs": [],
      "source": [
        "cartesian_points = get_cartesian_points_from_mask(processed_mask, study_area_image.shape[:2])\n",
        "\n",
        "# Convert each row to a tuple for set operations.\n",
        "set_cartesian = set(map(tuple, cartesian_points))\n",
        "set_fil = set(map(tuple, median_feature_points))\n",
        "\n",
        "# Get the intersection (points that appear in both).\n",
        "common_points_set = set_cartesian.intersection(set_fil)\n",
        "\n",
        "# Convert back to a NumPy array.\n",
        "ts_points = np.array(list(common_points_set))\n",
        "\n",
        "displacement_data = accumulate_displacement_with_placeholders(\n",
        "    filtered_all_u, filtered_all_v, filtered_all_feature_points, separation, ts_points, dat1, dat2, pixel_size, all_pkrs, all_snrs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0026635",
      "metadata": {
        "id": "c0026635"
      },
      "source": [
        "\n",
        "Reconstructs pixel-wise displacement time series and estimates average velocity from pairwise results.\n",
        "\n",
        "üß† **Tip**: Use `'weighted'` for better handling of irregular observation frequency and variable data quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vikVsfs3O1te",
      "metadata": {
        "id": "vikVsfs3O1te"
      },
      "outputs": [],
      "source": [
        "method = 'lsqr' # 'weighted' or 'midpoint' or 'lsqr'\n",
        "months_per_bin = 6\n",
        "min_snr=3\n",
        "min_pkr=1.3\n",
        "\n",
        "# the following are just for lsqr\n",
        "time_step='3M' # Solve for velocity every n months\n",
        "weight_by='snr' # Weight by snr or pkr ratio\n",
        "\n",
        "velocity_estimates = estimate_velocity_time_series(\n",
        "    displacement_data,\n",
        "    method=method,\n",
        "    months_per_bin=months_per_bin,\n",
        "    min_snr=min_snr,\n",
        "    min_pkr=min_pkr,\n",
        "    time_step=time_step,\n",
        "    weight_by=weight_by,\n",
        "    velocity_units='m/year'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gfMgQD9jdvmm",
      "metadata": {
        "id": "gfMgQD9jdvmm"
      },
      "source": [
        "Create Multiband .tif (creates 1 georeferenced map for each time step in the time series)\n",
        "\n",
        "Create a .gif time lapse of the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23984508",
      "metadata": {
        "id": "23984508"
      },
      "outputs": [],
      "source": [
        "tif_path = f\"{output_dir}/{output_dir}_magnitude_multiband.tif\"\n",
        "output_gif = f\"{output_dir}/{output_dir}_magnitude_multiband.gif\"\n",
        "\n",
        "create_multiband_magnitude_tif(velocity_estimates, study_area_image, output_dir, block_size, overlap, output_filename=f\"{output_dir}_magnitude_multiband.tif\")\n",
        "\n",
        "# study_area_image should be loaded as a NumPy array and have the same resolution as your composite.\n",
        "create_gif_with_background_and_colorbar(tif_path, study_area_image, output_gif, duration=1000.0, cmap=\"viridis\", alpha=0.6, velocity_estimates=velocity_estimates)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xmbc1c6jeCne",
      "metadata": {
        "id": "xmbc1c6jeCne"
      },
      "source": [
        "Save time series WE, NS and Magnitude in files compatible with InSAR Explorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df3cacb2",
      "metadata": {
        "id": "df3cacb2"
      },
      "outputs": [],
      "source": [
        "# Create velocity time series CSVs with median velocities for EW and SN components\n",
        "csv_data_we, csv_data_ns, csv_data_mag = prepare_csv_with_components(velocity_estimates, geotiff_path=f'{output_dir}/S2_Composite_Filtered_8bit.tif')\n",
        "\n",
        "# Save to CSV (optional)\n",
        "csv_data_we.to_csv(f'{output_dir}/velocity_time_series_we.csv', index=False)\n",
        "csv_data_ns.to_csv(f'{output_dir}/velocity_time_series_ns.csv', index=False)\n",
        "csv_data_mag.to_csv(f'{output_dir}/velocity_time_series_mag.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P7AjvNNZykUi",
      "metadata": {
        "id": "P7AjvNNZykUi"
      },
      "outputs": [],
      "source": [
        "# Plot fastes points\n",
        "plot_fastest_points_components(csv_data_we, csv_data_ns, top_n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Oi3gFudTymLi",
      "metadata": {
        "id": "Oi3gFudTymLi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "from rasterio.warp import transform_bounds\n",
        "import pandas as pd\n",
        "\n",
        "# Paths to input files\n",
        "geotiff_path = f'{output_dir}/S2_Composite_Filtered_8bit.tif'\n",
        "csv_ew_path = f'{output_dir}/velocity_time_series_we.csv'\n",
        "csv_sn_path = f'{output_dir}/velocity_time_series_ns.csv'\n",
        "\n",
        "# Load CSVs\n",
        "csv_data_ew = pd.read_csv(csv_ew_path)\n",
        "csv_data_sn = pd.read_csv(csv_sn_path)\n",
        "\n",
        "# Combine WE and NS velocities into a single DataFrame\n",
        "csv_data_ew['mean_velocity'] = (csv_data_ew['median_velocity']**2 + csv_data_sn['median_velocity']**2)**0.5\n",
        "\n",
        "# Load GeoTIFF image and get transform & CRS\n",
        "with rasterio.open(geotiff_path) as src:\n",
        "    image = src.read(1)  # Read the first band\n",
        "    transform = src.transform\n",
        "    src_crs = src.crs\n",
        "\n",
        "    # Get image bounds in the native CRS\n",
        "    left = transform[2]\n",
        "    top = transform[5]\n",
        "    right = left + transform[0] * image.shape[1]\n",
        "    bottom = top + transform[4] * image.shape[0]\n",
        "\n",
        "    # Transform bounds to EPSG:84 (WGS84) so they match the CSV lat/lon\n",
        "    bounds_84 = transform_bounds(src_crs, 'EPSG:4326', left, bottom, right, top)\n",
        "\n",
        "# bounds_84 is in the order (min_lon, min_lat, max_lon, max_lat)\n",
        "xmin, ymin, xmax, ymax = bounds_84\n",
        "\n",
        "# Plot the image using the transformed bounds\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(image, cmap='gray', extent=[xmin, xmax, ymin, ymax])\n",
        "plt.title('Mean Velocity from Time Series Overlaid on Image')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "\n",
        "# Overlay mean velocity as scatter points (CSV coordinates assumed to be in EPSG:84)\n",
        "scatter = plt.scatter(\n",
        "    csv_data_ew['longitude'], csv_data_ew['latitude'],\n",
        "    c=csv_data_ew['mean_velocity'], cmap='coolwarm', s=15, edgecolor='k', alpha=0.7\n",
        ")\n",
        "plt.colorbar(scatter, label='Mean Velocity (m/year)')\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LfThERh74RWa",
      "metadata": {
        "id": "LfThERh74RWa"
      },
      "source": [
        "### ‚¨áÔ∏è Downloading Outputs\n",
        "\n",
        "To download files directly from Colab to your computer. This creates a zip of the entire outputs folder and downloads it to device.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HssiSFAbypwW",
      "metadata": {
        "id": "HssiSFAbypwW"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive(f'Terratrack_Results_{output_dir}', 'zip', 'outputs')\n",
        "\n",
        "# Download\n",
        "files.download(f'Terratrack_Results_{output_dir}.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zs7guq8eTlRy",
      "metadata": {
        "id": "Zs7guq8eTlRy"
      },
      "outputs": [],
      "source": [
        "# Run this after the cells above to set an alert sound when the processing is finished\n",
        "play_alert()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Sgbckihq0fku",
      "metadata": {
        "id": "Sgbckihq0fku"
      },
      "source": [
        "# Inverse Velocity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uCPKxzm50iKU",
      "metadata": {
        "id": "uCPKxzm50iKU"
      },
      "outputs": [],
      "source": [
        "component = 'mag' # 'we', 'ns', 'mag'\n",
        "failure_dates_list = compute_inverse_velocity_failure_dates(f\"Chaos/velocity_time_series_{component}.csv\", n_points_for_fit_list=[4,5,6,7])\n",
        "failure_counts = failure_date_statistics(failure_dates_list)\n",
        "plot_failure_distribution(failure_counts)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "terratrack",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}